{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SINgle CelL AnalysIs Resource (SINCLAIR) \u00b6 The SINCLAIR pipeline was developed by the CCR Collaborative Bioinformatics Resource as an open-source, reproducible solution for multiple single cell next-generation modalities. It has been developed and tested solely on NIH HPC Biowulf . Overview of Single Cell RNASeq Gene Expression Pipeline","title":"Background"},{"location":"#single-cell-analysis-resource-sinclair","text":"The SINCLAIR pipeline was developed by the CCR Collaborative Bioinformatics Resource as an open-source, reproducible solution for multiple single cell next-generation modalities. It has been developed and tested solely on NIH HPC Biowulf . Overview of Single Cell RNASeq Gene Expression Pipeline","title":"SINgle CelL AnalysIs Resource (SINCLAIR)"},{"location":"contributing/","text":"Contributing to SINCLAIR \u00b6 Proposing changes with issues \u00b6 If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it. Pull request process \u00b6 We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to SINCLAIR. Clone the repo \u00b6 If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/SINCLAIR Cloning into 'SINCLAIR'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd SINCLAIR If this is your first time cloning the repo, you may need to install dependencies \u00b6 Install nextflow and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo. Create a branch \u00b6 Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10' Make your changes \u00b6 Edit the code, write and run tests, and update the documentation as needed. test \u00b6 Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended. document \u00b6 If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ . Commit and push your changes \u00b6 If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/SINCLAIR/pull/new/iss-10 remote: To https://github.com/CCBR/SINCLAIR > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/SINCLAIR/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch). Create the PR \u00b6 Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/SINCLAIR/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready. Wait for a maintainer to review your PR \u00b6 We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution! After your PR has been merged \u00b6 After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main. Helpful links for more information \u00b6 GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"How to contribute"},{"location":"contributing/#contributing-to-sinclair","text":"","title":"Contributing to SINCLAIR"},{"location":"contributing/#proposing-changes-with-issues","text":"If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it.","title":"Proposing changes with issues"},{"location":"contributing/#pull-request-process","text":"We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to SINCLAIR.","title":"Pull request process"},{"location":"contributing/#clone-the-repo","text":"If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/SINCLAIR Cloning into 'SINCLAIR'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd SINCLAIR","title":"Clone the repo"},{"location":"contributing/#if-this-is-your-first-time-cloning-the-repo-you-may-need-to-install-dependencies","text":"Install nextflow and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo.","title":"If this is your first time cloning the repo, you may need to install dependencies"},{"location":"contributing/#create-a-branch","text":"Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10'","title":"Create a branch"},{"location":"contributing/#make-your-changes","text":"Edit the code, write and run tests, and update the documentation as needed.","title":"Make your changes"},{"location":"contributing/#test","text":"Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended.","title":"test"},{"location":"contributing/#document","text":"If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ .","title":"document"},{"location":"contributing/#commit-and-push-your-changes","text":"If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/SINCLAIR/pull/new/iss-10 remote: To https://github.com/CCBR/SINCLAIR > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/SINCLAIR/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch).","title":"Commit and push your changes"},{"location":"contributing/#create-the-pr","text":"Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/SINCLAIR/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready.","title":"Create the PR"},{"location":"contributing/#wait-for-a-maintainer-to-review-your-pr","text":"We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!","title":"Wait for a maintainer to review your PR"},{"location":"contributing/#after-your-pr-has-been-merged","text":"After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main.","title":"After your PR has been merged"},{"location":"contributing/#helpful-links-for-more-information","text":"GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"Helpful links for more information"},{"location":"release-guide/","text":"Release Guide \u00b6 How to test a pre-release on biowulf \u00b6 Install the development version of sinclair. # activate the conda env for development . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 # go to the source on biowulf and update cd /data/CCBR_Pipeliner/Pipelines/SINCLAIR/dev git pull # optionally switch to different branch if needed # install the version to a hidden path (e.g. .v0.2.0-dev) in /data/CCBR_Pipeliner/Pipelines/SINCLAIR cd .. pip install ./dev -t ./.v0.2.0-dev # add it to your PATH and PYTHONPATH with: export PATH = \" $PATH :/data/CCBR_Pipeliner/Pipelines/SINCLAIR/.v0.2.0-dev/bin/\" export PYTHONPATH = \" $PYTHONPATH :/data/CCBR_Pipeliner/Pipelines/SINCLAIR/.v0.2.0-dev/\"","title":"Release Guide"},{"location":"release-guide/#release-guide","text":"","title":"Release Guide"},{"location":"release-guide/#how-to-test-a-pre-release-on-biowulf","text":"Install the development version of sinclair. # activate the conda env for development . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 # go to the source on biowulf and update cd /data/CCBR_Pipeliner/Pipelines/SINCLAIR/dev git pull # optionally switch to different branch if needed # install the version to a hidden path (e.g. .v0.2.0-dev) in /data/CCBR_Pipeliner/Pipelines/SINCLAIR cd .. pip install ./dev -t ./.v0.2.0-dev # add it to your PATH and PYTHONPATH with: export PATH = \" $PATH :/data/CCBR_Pipeliner/Pipelines/SINCLAIR/.v0.2.0-dev/bin/\" export PYTHONPATH = \" $PYTHONPATH :/data/CCBR_Pipeliner/Pipelines/SINCLAIR/.v0.2.0-dev/\"","title":"How to test a pre-release on biowulf"},{"location":"user-guide/contributions/","text":"Contributions \u00b6 The following members contributed to the development of the scRNA pipeline: Abdalla Abdelmaksoud Nathan Wong Samantha Sevilla Vishal Koparde AA, NW, SS contributed to the generating the source code and all members contributed to the main concepts and analysis.","title":"Contributors"},{"location":"user-guide/contributions/#contributions","text":"The following members contributed to the development of the scRNA pipeline: Abdalla Abdelmaksoud Nathan Wong Samantha Sevilla Vishal Koparde AA, NW, SS contributed to the generating the source code and all members contributed to the main concepts and analysis.","title":"Contributions"},{"location":"user-guide/differentialExpression/","text":"Running Differential Expression \u00b6 Adapted from the Seurat differential expression vignette When running differential expression on the Seurat object produced by SINCLAIR, these steps should be followed to ensure an accurate output Choosing the identities \u00b6 Before running any sort of differential expression, the identities of the Seurat object need to be determined and set by the user. For example, the following code will set the Seurat object identities to the clusters found at resolution 0.8: Idents(seuratObject) = \"SCT_snn_res.0.8\" The identities are not limited to the clusters; these can be set to any categorical variable in the metadata, including cell types that have been determined by SingleR or classified by the user, cell cycle phase (G1/G2M/S), or experimental group. Preparing the Seurat object for differential expression with PrepSCTFindMarkers \u00b6 After defining the object identities, Seurat requires that when when running differential expression on the SCT assay, the object needs to be prepared with the PrepSCTFindMarkers function: seuratObject = PrepSCTFindMarkers(seuratObject) The purpose of the PrepSCTFindMarkers is to use the minimum of the median UMI of individual objects to appropriately scale the SCT assay prior to differential expression ref . Finding differentially expressed genes in Seurat \u00b6 Two options are available when running differential expression through Seurat. Option 1: Running FindMarkers ref \u00b6 The \"traditional\" method of running differential expression compares two separate categories; this can still be exercised in the presence of more than the two comparison groups of interest. Following the example above, comparing the two largest clusters as determined by Seurat would be run as follows: deGeneList = FindMarkers(seuratObject,ident.1=0,ident.2=1,test.use = \"MAST\") By default, Seurat uses the non-parametric Wilcoxon rank-sum test to identify significant genes. The MAST ref algorithm uses a hurdle model to account for the sparsity of scRNASeq count matrices, and tends to be more sensitive to likely changes. Option 2: Running FindAllMarkers ref \u00b6 When looking to define a set of potential clusters or identities using gene markers, the FindAllMarkers function will run the differential expression by setting the first identity group (equivalent to ident.1 ) to each cluster in turn and using the remaining clusters as the comparison group ( ident.2 ). markerGeneList = FindAllMarkers(seuratObject,test.use=\"MAST\") The resulting list will show the differentially expressed genes that are significantly enriched or depleted for each identity within the preselected category. In essence, FindAllMarkers runs a loop where FindMarkers is run for each individual identity. Alternative methods for differential expression \u00b6 The default values for some of the more frequently altered parameters for the FindMarkers and FindAllMarkers functions are as follows: deGenes = FindMarkers(seuratObject, ident.1=NA, ident.2=NA, features=NULL, test.use=\"wilcox,\" logfc.threshold=0.25, min.pct=0.1) If ident.1 is defined and ident.2 is left as a NULL value, the cells not included in ident.1 will be used as the comparison, i.e. essentially running a one vs. rest comparison, similar to what is described in FindAllMarkers . The features parameter can take a vector of specified genes and only run differential expression for those genes. Note that this assumes that the gene is not filtered out by any other criteria, such as those listed below. In all other cases, all genes are run through initial filtering and statistical testing. The test.use parameter is used to change the statistical test applied to identify differentially expressed genes. As mentioned above, the MAST algorithm is often applied to single cell data, while other tests that can be applied include \"bimod\" , \"roc\" , \"t\" , \"negbinom\" , \"poisson\" , \"LR\" , and \"DESeq2\" . The logfc.threshold filters out all genes that do not meet a log2 fold change threshold. This is applied to improve the speed of the computation, as those genes that do not meet this value are not subjected to statistical testing. The default threshold value is 0.25, which is roughly a 20% average fold change. The min.pct threshold filters out genes that are not expressed in the fraction of cells below the threshold for both comparison groups. If only one comparison group is below the threshold, the statistics for the gene will still be calculated. The default min.pct threshold is 0.1, or 10%. Since a number of genes will be unaffected by the experiment, a full differential expression list will require setting both logfc.threshold and min.pct to 0, so as to calculate the statistics for less relevant genes. These parameters may also need to be adjusted when selecting specific genes with the features parameter, as any user-defined genes that do not meet the threshold criteria will not be submitted to statistical testing. Expected outputs \u00b6 The output of the deGeneList variable above will have a table structure resembling the following: p_val avg_log2FC pct.1 pct.2 p_val_adj Tff1 2.27649774378448e-20 0.503646816090369 0.313 0.039 5.15945448651315e-16 Gkn1 2.37538488060338e-18 0.31537227402121 0.23 0.007 5.3835722933995e-14 Gkn2 9.91735374467266e-14 0.238583210040284 0.166 0.004 2.24766905269261e-09 Oaz1 1.26240861948424e-12 0.198987799763473 0.996 0.968 2.86112289519909e-08 Rab5c 3.39748073842636e-12 0.301705843310934 0.645 0.4 7.7000503455695e-08 Rbm3 5.53653902770416e-12 0.226144933696604 0.97 0.893 1.25480120523887e-07 Cfl1 9.22315807122862e-12 0.171800659275371 1 0.982 2.09033654526325e-07 Cd83 2.27101797312635e-10 0.242223105538207 0.849 0.789 5.14703513429356e-06 Tff2 2.66531282660886e-10 0.226607061165825 0.189 0.025 6.04066499022633e-06 The first unlabeled column lists the genes, followed by raw p-value, average log2 fold change, the percentage of cells expressing the gene in populations 1 and 2, and finally the adjusted p-value. The sign of the fold change and the definitions of pct.1 and pct.2 are defined by the order of groups selected in the FindMarkers call: Positive fold changes indicate enrichment in the first group (i.e. defined as ident.1 ), as well as the pct.1 value Common issues and questions \u00b6 Why are there so many genes with extremely small p-values? \u00b6 In most circumstances, a small p-value generally indicates that the gene is extremely significant and should not be ignored. However, many of the statistical tests that are designed based on distributions, including MAST, operate under a set of assumptions. With single cell, one of the assumptions that gets violated is an upper limit on the number of replicates included, since each individual cell is treated as a replicate and leads to a comparison of 2 groups with as many as tens of thousands of replicates each. Unfortunately, it falls to the user to determine the relative significance of the genes that are identified as significant by examining the other statistics provided (i.e. avg_log2FC and pct.1 / pct.2 ). Additionally, genes of interest can also be run through the AverageExpression and the FeaturePlot functions to explore the overall expression of the gene in the individual contrast groups. Other approaches, such as pseudobulk differential expression (see below) might be implemented in order to address this p-value phenomenon Requiring JoinLayers \u00b6 Since version 5, Seurat keeps individual samples as \"layers\" in the S4 data structure. This makes it simpler to apply various functions to each sample, such as SCTransform normalization or variable feature identification, since a single call to the Seurat object will behave like the lapply function in R. However, this also keeps the individual counts tables separate, which makes differential expression nigh impossible. To address this, the user needs to join the layers prior to running differential expression: so_dePrep = JoinLayers(seuratObject) so_dePrep = PrepSCTFindMarkers(so_dePrep) markers = FindAllMarkers(so_dePrep,test.use=\"MAST\") Running differential expression on subsets of cells \u00b6 Oftentimes the user will be interested in examining two different subsets of cells; for example, comparing the two experimental contrast groups in B cells alone. When isolating a group with the subset in question, the user might send a command such as: Bcells = subset(seuratObject,cells=colnames(seuratObject)[which(so$cellType==\"B cells\")]) However, when running FindMarkers on this subset, the following may be encountered: FindMarkers(Bcells,ident.1=\"group1\",test.use=\"MAST\") Error in FindMarkers.SCTAssay(object = data.use, slot = slot, cells.1 = cells$cells.1, : Object contains multiple models with unequal library sizes. Run `PrepSCTFindMarkers()` before running `FindMarkers()`. In this event, the user should ensure that the subset was extracted from the Seurat object that has already been prepared through PrepSCTFindMarkers to ensure appropriate scaling. The second step is to use a hidden parameter recorrect_umi to tell the program to \"ignore\" the scaling step. FindMarkers(Bcells,ident.1=\"group1\",test.use=\"MAST\", recorrect_umi=FALSE) In theory, this flag can also be used in all other steps in order to skip the scaling step for differential expression, but this is generally not recommended. Pseudobulk differential expression \u00b6 If there are enough individual replicates, a user can convert the single cell dataset into a pseudobulk dataset and treat the individual samples as pooled replicates to be submitted through a standard RNASeq differential expression protocol, such as Limma or DESeq2. This has been explored using the Libra tool and through Seurat using their AggregateExpression function. The results tend to increase the p-values, which subsequently reduces the likelihood of false positives in identifying differentially expressed genes. The main warning when running a pseudobulk approach is to ensure that there are enough samples to warrant aggregation; if only one sample is available per experimental condition, the user will be attempting a 1v1 differential expression design, which is not nearly robust enough to account for any intra-group sample variability. References: 1. PrepSCTFindMarkers 2. FindMarkers 3. FindAllMarkers Author: Nathan Wong. January 2023","title":"1. Differential Expression Analysis"},{"location":"user-guide/differentialExpression/#running-differential-expression","text":"Adapted from the Seurat differential expression vignette When running differential expression on the Seurat object produced by SINCLAIR, these steps should be followed to ensure an accurate output","title":"Running Differential Expression"},{"location":"user-guide/differentialExpression/#choosing-the-identities","text":"Before running any sort of differential expression, the identities of the Seurat object need to be determined and set by the user. For example, the following code will set the Seurat object identities to the clusters found at resolution 0.8: Idents(seuratObject) = \"SCT_snn_res.0.8\" The identities are not limited to the clusters; these can be set to any categorical variable in the metadata, including cell types that have been determined by SingleR or classified by the user, cell cycle phase (G1/G2M/S), or experimental group.","title":"Choosing the identities"},{"location":"user-guide/differentialExpression/#preparing-the-seurat-object-for-differential-expression-with-prepsctfindmarkers","text":"After defining the object identities, Seurat requires that when when running differential expression on the SCT assay, the object needs to be prepared with the PrepSCTFindMarkers function: seuratObject = PrepSCTFindMarkers(seuratObject) The purpose of the PrepSCTFindMarkers is to use the minimum of the median UMI of individual objects to appropriately scale the SCT assay prior to differential expression ref .","title":"Preparing the Seurat object for differential expression with PrepSCTFindMarkers"},{"location":"user-guide/differentialExpression/#finding-differentially-expressed-genes-in-seurat","text":"Two options are available when running differential expression through Seurat.","title":"Finding differentially expressed genes in Seurat"},{"location":"user-guide/differentialExpression/#option-1-running-findmarkersref","text":"The \"traditional\" method of running differential expression compares two separate categories; this can still be exercised in the presence of more than the two comparison groups of interest. Following the example above, comparing the two largest clusters as determined by Seurat would be run as follows: deGeneList = FindMarkers(seuratObject,ident.1=0,ident.2=1,test.use = \"MAST\") By default, Seurat uses the non-parametric Wilcoxon rank-sum test to identify significant genes. The MAST ref algorithm uses a hurdle model to account for the sparsity of scRNASeq count matrices, and tends to be more sensitive to likely changes.","title":"Option 1: Running FindMarkersref"},{"location":"user-guide/differentialExpression/#option-2-running-findallmarkersref","text":"When looking to define a set of potential clusters or identities using gene markers, the FindAllMarkers function will run the differential expression by setting the first identity group (equivalent to ident.1 ) to each cluster in turn and using the remaining clusters as the comparison group ( ident.2 ). markerGeneList = FindAllMarkers(seuratObject,test.use=\"MAST\") The resulting list will show the differentially expressed genes that are significantly enriched or depleted for each identity within the preselected category. In essence, FindAllMarkers runs a loop where FindMarkers is run for each individual identity.","title":"Option 2: Running FindAllMarkersref"},{"location":"user-guide/differentialExpression/#alternative-methods-for-differential-expression","text":"The default values for some of the more frequently altered parameters for the FindMarkers and FindAllMarkers functions are as follows: deGenes = FindMarkers(seuratObject, ident.1=NA, ident.2=NA, features=NULL, test.use=\"wilcox,\" logfc.threshold=0.25, min.pct=0.1) If ident.1 is defined and ident.2 is left as a NULL value, the cells not included in ident.1 will be used as the comparison, i.e. essentially running a one vs. rest comparison, similar to what is described in FindAllMarkers . The features parameter can take a vector of specified genes and only run differential expression for those genes. Note that this assumes that the gene is not filtered out by any other criteria, such as those listed below. In all other cases, all genes are run through initial filtering and statistical testing. The test.use parameter is used to change the statistical test applied to identify differentially expressed genes. As mentioned above, the MAST algorithm is often applied to single cell data, while other tests that can be applied include \"bimod\" , \"roc\" , \"t\" , \"negbinom\" , \"poisson\" , \"LR\" , and \"DESeq2\" . The logfc.threshold filters out all genes that do not meet a log2 fold change threshold. This is applied to improve the speed of the computation, as those genes that do not meet this value are not subjected to statistical testing. The default threshold value is 0.25, which is roughly a 20% average fold change. The min.pct threshold filters out genes that are not expressed in the fraction of cells below the threshold for both comparison groups. If only one comparison group is below the threshold, the statistics for the gene will still be calculated. The default min.pct threshold is 0.1, or 10%. Since a number of genes will be unaffected by the experiment, a full differential expression list will require setting both logfc.threshold and min.pct to 0, so as to calculate the statistics for less relevant genes. These parameters may also need to be adjusted when selecting specific genes with the features parameter, as any user-defined genes that do not meet the threshold criteria will not be submitted to statistical testing.","title":"Alternative methods for differential expression"},{"location":"user-guide/differentialExpression/#expected-outputs","text":"The output of the deGeneList variable above will have a table structure resembling the following: p_val avg_log2FC pct.1 pct.2 p_val_adj Tff1 2.27649774378448e-20 0.503646816090369 0.313 0.039 5.15945448651315e-16 Gkn1 2.37538488060338e-18 0.31537227402121 0.23 0.007 5.3835722933995e-14 Gkn2 9.91735374467266e-14 0.238583210040284 0.166 0.004 2.24766905269261e-09 Oaz1 1.26240861948424e-12 0.198987799763473 0.996 0.968 2.86112289519909e-08 Rab5c 3.39748073842636e-12 0.301705843310934 0.645 0.4 7.7000503455695e-08 Rbm3 5.53653902770416e-12 0.226144933696604 0.97 0.893 1.25480120523887e-07 Cfl1 9.22315807122862e-12 0.171800659275371 1 0.982 2.09033654526325e-07 Cd83 2.27101797312635e-10 0.242223105538207 0.849 0.789 5.14703513429356e-06 Tff2 2.66531282660886e-10 0.226607061165825 0.189 0.025 6.04066499022633e-06 The first unlabeled column lists the genes, followed by raw p-value, average log2 fold change, the percentage of cells expressing the gene in populations 1 and 2, and finally the adjusted p-value. The sign of the fold change and the definitions of pct.1 and pct.2 are defined by the order of groups selected in the FindMarkers call: Positive fold changes indicate enrichment in the first group (i.e. defined as ident.1 ), as well as the pct.1 value","title":"Expected outputs"},{"location":"user-guide/differentialExpression/#common-issues-and-questions","text":"","title":"Common issues and questions"},{"location":"user-guide/differentialExpression/#why-are-there-so-many-genes-with-extremely-small-p-values","text":"In most circumstances, a small p-value generally indicates that the gene is extremely significant and should not be ignored. However, many of the statistical tests that are designed based on distributions, including MAST, operate under a set of assumptions. With single cell, one of the assumptions that gets violated is an upper limit on the number of replicates included, since each individual cell is treated as a replicate and leads to a comparison of 2 groups with as many as tens of thousands of replicates each. Unfortunately, it falls to the user to determine the relative significance of the genes that are identified as significant by examining the other statistics provided (i.e. avg_log2FC and pct.1 / pct.2 ). Additionally, genes of interest can also be run through the AverageExpression and the FeaturePlot functions to explore the overall expression of the gene in the individual contrast groups. Other approaches, such as pseudobulk differential expression (see below) might be implemented in order to address this p-value phenomenon","title":"Why are there so many genes with extremely small p-values?"},{"location":"user-guide/differentialExpression/#requiring-joinlayers","text":"Since version 5, Seurat keeps individual samples as \"layers\" in the S4 data structure. This makes it simpler to apply various functions to each sample, such as SCTransform normalization or variable feature identification, since a single call to the Seurat object will behave like the lapply function in R. However, this also keeps the individual counts tables separate, which makes differential expression nigh impossible. To address this, the user needs to join the layers prior to running differential expression: so_dePrep = JoinLayers(seuratObject) so_dePrep = PrepSCTFindMarkers(so_dePrep) markers = FindAllMarkers(so_dePrep,test.use=\"MAST\")","title":"Requiring JoinLayers"},{"location":"user-guide/differentialExpression/#running-differential-expression-on-subsets-of-cells","text":"Oftentimes the user will be interested in examining two different subsets of cells; for example, comparing the two experimental contrast groups in B cells alone. When isolating a group with the subset in question, the user might send a command such as: Bcells = subset(seuratObject,cells=colnames(seuratObject)[which(so$cellType==\"B cells\")]) However, when running FindMarkers on this subset, the following may be encountered: FindMarkers(Bcells,ident.1=\"group1\",test.use=\"MAST\") Error in FindMarkers.SCTAssay(object = data.use, slot = slot, cells.1 = cells$cells.1, : Object contains multiple models with unequal library sizes. Run `PrepSCTFindMarkers()` before running `FindMarkers()`. In this event, the user should ensure that the subset was extracted from the Seurat object that has already been prepared through PrepSCTFindMarkers to ensure appropriate scaling. The second step is to use a hidden parameter recorrect_umi to tell the program to \"ignore\" the scaling step. FindMarkers(Bcells,ident.1=\"group1\",test.use=\"MAST\", recorrect_umi=FALSE) In theory, this flag can also be used in all other steps in order to skip the scaling step for differential expression, but this is generally not recommended.","title":"Running differential expression on subsets of cells"},{"location":"user-guide/differentialExpression/#pseudobulk-differential-expression","text":"If there are enough individual replicates, a user can convert the single cell dataset into a pseudobulk dataset and treat the individual samples as pooled replicates to be submitted through a standard RNASeq differential expression protocol, such as Limma or DESeq2. This has been explored using the Libra tool and through Seurat using their AggregateExpression function. The results tend to increase the p-values, which subsequently reduces the likelihood of false positives in identifying differentially expressed genes. The main warning when running a pseudobulk approach is to ensure that there are enough samples to warrant aggregation; if only one sample is available per experimental condition, the user will be attempting a 1v1 differential expression design, which is not nearly robust enough to account for any intra-group sample variability. References: 1. PrepSCTFindMarkers 2. FindMarkers 3. FindAllMarkers Author: Nathan Wong. January 2023","title":"Pseudobulk differential expression"},{"location":"user-guide/getting-started/","text":"Overview \u00b6 The scRNA github repository is stored locally, and will be used for project deployment. Multiple projects can be deployed from this one point simultaneously, without concern. 1. Getting Started \u00b6 1.1 Introduction \u00b6 The scRNA Pipelie beings at various stages, depending on the users needs. The pipeline can begin with GEX FASTQ files, performing cell counting, with 10X Genomic's CellRanger . Then, normalization and pre-processing occurs, using custom R scripts with packages like Seurat . Alternatively the user can begin with .h5 files, beginning the pipeline post-preprocessing. [TODO: add as we go!] 1.2 Setup Dependencies \u00b6 scRNA has several dependencies listed below. These dependencies can be installed by a sysadmin. All dependencies will be automatically loaded if running from Biowulf. nextflow: \"nextflow/23.04.1\" cellranger \"cellranger:7.1.0\" R: \"R/4.3\" Docker containers to run the pipeline are currently in development. 1.3 Login to the cluster \u00b6 scRNA has been exclusively tested on Biowulf HPC. Login to the cluster's head node and move into the pipeline location. # ssh into cluster's head node ssh -Y $USER@biowulf.nih.gov 1.4 Load an interactive session \u00b6 An interactive session should be started before performing any of the pipeline sub-commands, even if the pipeline is to be executed on the cluster. # Grab an interactive node sinteractive --time=12:00:00 --mem=8gb --cpus-per-task=4 --pty bash","title":"1. Getting Started"},{"location":"user-guide/getting-started/#overview","text":"The scRNA github repository is stored locally, and will be used for project deployment. Multiple projects can be deployed from this one point simultaneously, without concern.","title":"Overview"},{"location":"user-guide/getting-started/#1-getting-started","text":"","title":"1. Getting Started"},{"location":"user-guide/getting-started/#11-introduction","text":"The scRNA Pipelie beings at various stages, depending on the users needs. The pipeline can begin with GEX FASTQ files, performing cell counting, with 10X Genomic's CellRanger . Then, normalization and pre-processing occurs, using custom R scripts with packages like Seurat . Alternatively the user can begin with .h5 files, beginning the pipeline post-preprocessing. [TODO: add as we go!]","title":"1.1 Introduction"},{"location":"user-guide/getting-started/#12-setup-dependencies","text":"scRNA has several dependencies listed below. These dependencies can be installed by a sysadmin. All dependencies will be automatically loaded if running from Biowulf. nextflow: \"nextflow/23.04.1\" cellranger \"cellranger:7.1.0\" R: \"R/4.3\" Docker containers to run the pipeline are currently in development.","title":"1.2 Setup Dependencies"},{"location":"user-guide/getting-started/#13-login-to-the-cluster","text":"scRNA has been exclusively tested on Biowulf HPC. Login to the cluster's head node and move into the pipeline location. # ssh into cluster's head node ssh -Y $USER@biowulf.nih.gov","title":"1.3 Login to the cluster"},{"location":"user-guide/getting-started/#14-load-an-interactive-session","text":"An interactive session should be started before performing any of the pipeline sub-commands, even if the pipeline is to be executed on the cluster. # Grab an interactive node sinteractive --time=12:00:00 --mem=8gb --cpus-per-task=4 --pty bash","title":"1.4 Load an interactive session"},{"location":"user-guide/output/","text":"4. Expected Outputs \u00b6 The following directories are created under the WORKDIR directory: batch_correct: contains the various RDS files for batch correction methods ( CCA , HARMONY, ScVI, RPCA, LIGER) and batch correction report (HTML) cellranger_counts: contains the h5 files, if cellranger count is deployed pipeline_info: contains execution_reports, execution_trace and pipeline_dag files from NextFlow samplesheets: contains the manifests used to identify samples, contrasts, and sample:contrast groupings seurat: contains multiple seurat-generated directories: preprocess: contains sample level data; both RDS and PDF files from pre-processing merge: contrast grouped, sample level data; both RDS and PDf files of pre-processed, merging \u2500 batch_correct \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_cca.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_harmony.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_integration.html \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_liger.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_rpca.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_scvi.rds \u251c\u2500\u2500 cellranger_counts \u2502 \u251c\u2500\u2500 sample1 \u2502 \u2502 \u2514\u2500\u2500 outs \u2502 \u2502 \u2514\u2500\u2500 filtered_feature_bc_matrix.h5 \u251c\u2500\u2500 pipeline_info \u2502 \u251c\u2500\u2500 execution_report_2023-09-20_12-45-47.html \u2502 \u251c\u2500\u2500 execution_timeline_2023-09-20_12-45-47.html \u2502 \u251c\u2500\u2500 execution_trace_2023-09-20_12-45-47.txt \u2502 \u2514\u2500\u2500 pipeline_dag_2023-09-20_12-45-47.svg \u251c\u2500\u2500 samplesheets \u2502 \u251c\u2500\u2500 project_contrast_samplesheet.csv \u2502 \u251c\u2500\u2500 project_gex_samplesheet.csv \u2502 \u2514\u2500\u2500 project_groups_samplesheet.csv \u2514\u2500\u2500 seurat \u251c\u2500\u2500 merge \u2502 \u251c\u2500\u2500 group1-group2_seurat_merged.pdf \u2502 \u2514\u2500\u2500 group1-group2_seurat_merged.rds \u2514\u2500\u2500 preprocess \u251c\u2500\u2500 sample1_seurat_preprocess.pdf \u251c\u2500\u2500 sample1_seurat_preprocess.rds","title":"4. Expected Output"},{"location":"user-guide/output/#4-expected-outputs","text":"The following directories are created under the WORKDIR directory: batch_correct: contains the various RDS files for batch correction methods ( CCA , HARMONY, ScVI, RPCA, LIGER) and batch correction report (HTML) cellranger_counts: contains the h5 files, if cellranger count is deployed pipeline_info: contains execution_reports, execution_trace and pipeline_dag files from NextFlow samplesheets: contains the manifests used to identify samples, contrasts, and sample:contrast groupings seurat: contains multiple seurat-generated directories: preprocess: contains sample level data; both RDS and PDF files from pre-processing merge: contrast grouped, sample level data; both RDS and PDf files of pre-processed, merging \u2500 batch_correct \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_cca.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_harmony.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_integration.html \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_liger.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_rpca.rds \u2502 \u251c\u2500\u2500 group1-group2_batch_correction_scvi.rds \u251c\u2500\u2500 cellranger_counts \u2502 \u251c\u2500\u2500 sample1 \u2502 \u2502 \u2514\u2500\u2500 outs \u2502 \u2502 \u2514\u2500\u2500 filtered_feature_bc_matrix.h5 \u251c\u2500\u2500 pipeline_info \u2502 \u251c\u2500\u2500 execution_report_2023-09-20_12-45-47.html \u2502 \u251c\u2500\u2500 execution_timeline_2023-09-20_12-45-47.html \u2502 \u251c\u2500\u2500 execution_trace_2023-09-20_12-45-47.txt \u2502 \u2514\u2500\u2500 pipeline_dag_2023-09-20_12-45-47.svg \u251c\u2500\u2500 samplesheets \u2502 \u251c\u2500\u2500 project_contrast_samplesheet.csv \u2502 \u251c\u2500\u2500 project_gex_samplesheet.csv \u2502 \u2514\u2500\u2500 project_groups_samplesheet.csv \u2514\u2500\u2500 seurat \u251c\u2500\u2500 merge \u2502 \u251c\u2500\u2500 group1-group2_seurat_merged.pdf \u2502 \u2514\u2500\u2500 group1-group2_seurat_merged.rds \u2514\u2500\u2500 preprocess \u251c\u2500\u2500 sample1_seurat_preprocess.pdf \u251c\u2500\u2500 sample1_seurat_preprocess.rds","title":"4. Expected Outputs"},{"location":"user-guide/preparing-files/","text":"2. Preparing Files \u00b6 The pipeline is controlled through editing configuration and manifest files. Defaults are found in the /PIPELINEDIR/conf and /PIPELINEDIR/ directories Overview of Single Cell RNASeq Gene Expression Process 2.1 Configs \u00b6 The configuration files control parameters and software of the pipeline. These files are listed below: nextflow.config conf/base.config conf/modules.config conf/process_params.config conf/Rpack.config 2.1.1 NextFlow Config \u00b6 The configuration file dictates the global information to be used during the pipeline. Users can alter the default values, as needed: - input: path to input manifest; example manifests with ( input_manifest_cellranger.csv ) and without ( input_manifest.csv ) cellranger are included in assets - contrast: path to contrast manifest; example manifest ( contrast_manifest.csv ) is included in assets - outdir: path to output dir - species: species [options: hg19, mm10] - run_cellranger: determines whether to run cell ranger; if \"Y\" is selected, expects FQ inputs, if \"N\", expects .h5 inputs [options: \"Y\", \"N\"] - vars_to_regress: a comma separated list of any variables to regress during SCTransform process; [options: \"\", \"percent.mt,nFeature_RNA,S.Score,G2M.Score,nCount_RNA\"] 2.1.2 Base Config \u00b6 The configuration file dictates submission to Biowulf HPC. There are two different ways to control these parameters - first, to control the default settings, and second, to create or edit individual rules. These parameters should be edited with caution, after significant testing. 2.1.3 Modules Config \u00b6 The configuration file dictates process-specific processing parameters, including: the version of each software or program that is being used in the pipeline output location and file names additional arguments to be passed to the process 2.1.4 R Package Config \u00b6 The configuration file dictates which R libraries, and which versions, are loaded into the accompanying R script 2.1.3 Process Parameters \u00b6 The configuration file dictates process-specific user parameters, which varies for each process. Users can choose varied resolution values or QC methods, for example. 2.2 Preparing Manifests \u00b6 There are two manifests, which are required. These files describe information on the samples and desired contrasts. These files are: /assets/input_manifest.csv /assets/contrast_manifest.csv 2.2.1 Input Manifest \u00b6 This manifest will include information to sample level information. It includes the following column headers: masterID: This is the biological sample ID; duplicates are allowed in this column uniqueID: This is a unique sample level ID; duplicates are not allowed in this column groupID: This is the groupID which should match to the contrast_manifest ; duplicates are allowed in this column dataType: This is the datatype for the input sample; options are 'gex' 'atac' 'vdj' input_dir: This is the input directory for the data files of the sample type (IE \"/path/to/sample1/fastq\") An example sampleManifest file is shown below: | masterID | uniqueID | groupID | dataType | input_dir | | ---------- | -------- | ------- | --------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------- | | WB_Lysis_1 | sample1 | group1 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample1 | | WB_Lysis_1 | sample2 | group1 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample2 | | WB_Lysis_2 | sample3 | group2 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample3 | | WB_Lysis_2 | sample4 | group2 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample4 | | WB_Lysis_3 | sample5 | group3 | gex,/data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample5 | | WB_Lysis_1 | sample6 | group1 | atac | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample1 | 2.2.2 Contrast Manifest \u00b6 This manifest will include sample information to performed differential comparisons. A few requirements: groups listed must match groups within the input_manifest groupID column headers should be included for the max number of contrasts. In the example below, the second contrast contains 3 groups, and so the header includes contrast1-contrast3 multiple groups can be added by increasing the header and adding additional contrasts, as needed An example contrast file: contrast1 contrast2 contrast3 group1 group2 group1 group2 group3","title":"2. Preparing Files"},{"location":"user-guide/preparing-files/#2-preparing-files","text":"The pipeline is controlled through editing configuration and manifest files. Defaults are found in the /PIPELINEDIR/conf and /PIPELINEDIR/ directories Overview of Single Cell RNASeq Gene Expression Process","title":"2. Preparing Files"},{"location":"user-guide/preparing-files/#21-configs","text":"The configuration files control parameters and software of the pipeline. These files are listed below: nextflow.config conf/base.config conf/modules.config conf/process_params.config conf/Rpack.config","title":"2.1 Configs"},{"location":"user-guide/preparing-files/#211-nextflow-config","text":"The configuration file dictates the global information to be used during the pipeline. Users can alter the default values, as needed: - input: path to input manifest; example manifests with ( input_manifest_cellranger.csv ) and without ( input_manifest.csv ) cellranger are included in assets - contrast: path to contrast manifest; example manifest ( contrast_manifest.csv ) is included in assets - outdir: path to output dir - species: species [options: hg19, mm10] - run_cellranger: determines whether to run cell ranger; if \"Y\" is selected, expects FQ inputs, if \"N\", expects .h5 inputs [options: \"Y\", \"N\"] - vars_to_regress: a comma separated list of any variables to regress during SCTransform process; [options: \"\", \"percent.mt,nFeature_RNA,S.Score,G2M.Score,nCount_RNA\"]","title":"2.1.1 NextFlow Config"},{"location":"user-guide/preparing-files/#212-base-config","text":"The configuration file dictates submission to Biowulf HPC. There are two different ways to control these parameters - first, to control the default settings, and second, to create or edit individual rules. These parameters should be edited with caution, after significant testing.","title":"2.1.2 Base Config"},{"location":"user-guide/preparing-files/#213-modules-config","text":"The configuration file dictates process-specific processing parameters, including: the version of each software or program that is being used in the pipeline output location and file names additional arguments to be passed to the process","title":"2.1.3 Modules Config"},{"location":"user-guide/preparing-files/#214-r-package-config","text":"The configuration file dictates which R libraries, and which versions, are loaded into the accompanying R script","title":"2.1.4 R Package Config"},{"location":"user-guide/preparing-files/#213-process-parameters","text":"The configuration file dictates process-specific user parameters, which varies for each process. Users can choose varied resolution values or QC methods, for example.","title":"2.1.3 Process Parameters"},{"location":"user-guide/preparing-files/#22-preparing-manifests","text":"There are two manifests, which are required. These files describe information on the samples and desired contrasts. These files are: /assets/input_manifest.csv /assets/contrast_manifest.csv","title":"2.2 Preparing Manifests"},{"location":"user-guide/preparing-files/#221-input-manifest","text":"This manifest will include information to sample level information. It includes the following column headers: masterID: This is the biological sample ID; duplicates are allowed in this column uniqueID: This is a unique sample level ID; duplicates are not allowed in this column groupID: This is the groupID which should match to the contrast_manifest ; duplicates are allowed in this column dataType: This is the datatype for the input sample; options are 'gex' 'atac' 'vdj' input_dir: This is the input directory for the data files of the sample type (IE \"/path/to/sample1/fastq\") An example sampleManifest file is shown below: | masterID | uniqueID | groupID | dataType | input_dir | | ---------- | -------- | ------- | --------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------- | | WB_Lysis_1 | sample1 | group1 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample1 | | WB_Lysis_1 | sample2 | group1 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample2 | | WB_Lysis_2 | sample3 | group2 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample3 | | WB_Lysis_2 | sample4 | group2 | gex | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample4 | | WB_Lysis_3 | sample5 | group3 | gex,/data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample5 | | WB_Lysis_1 | sample6 | group1 | atac | /data/CCBR_Pipeliner/Pipelines/TechDev_scRNASeq_Dev2023/test_dir/ | WB_Lysis_Granulocytes_3p_Introns_8kCells_fastqs/sample1 |","title":"2.2.1 Input Manifest"},{"location":"user-guide/preparing-files/#222-contrast-manifest","text":"This manifest will include sample information to performed differential comparisons. A few requirements: groups listed must match groups within the input_manifest groupID column headers should be included for the max number of contrasts. In the example below, the second contrast contains 3 groups, and so the header includes contrast1-contrast3 multiple groups can be added by increasing the header and adding additional contrasts, as needed An example contrast file: contrast1 contrast2 contrast3 group1 group2 group1 group2 group3","title":"2.2.2 Contrast Manifest"},{"location":"user-guide/run/","text":"3. Running the Pipeline \u00b6 3.1 Pipeline Overview \u00b6 The Nextflow workflow can be run as follows: nextflow run main.nf \\ -entry $datatype \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /data/sevillas2/scRNA_test \\ --species $species \\ $args 3.2 Commands explained \u00b6 The following explains each of the command options: entry: accepts the datatype to be used; IE gex profile: how to run the processes; IE biowulf singularity, docker input: input_manifest.csv location contrast: contrast_manifest.csv location outdir: complete path to the output dir species: species to be used run_cellranger: whether or not to run cellranger on dataset; IE Y, N args: any additional arguments; IE --stub-run 3.3 Typical Workflow \u00b6 A typical command workflow, running the pipeline for the first time locally, is as follows: nextflow run main.nf \\ -entry gex \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --species hg19 A typical command workflow, running the pipeline for a repeated time locally, running cellranger, is as follows: nextflow run main.nf -resume \\ -entry gex \\ -profile biowulf \\ --run_cellranger Y \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --run_cellranger Y \\ --species hg19 A typical command workflow, running the pipeline in a dryrun mode , without running cellranger, is as follows: nextflow run main.nf \\ -entry gex \\ -profile biowulf \\ --run_cellranger Y \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --species hg19 \\ --run_cellranger N \\ --stub-run Alternatively a script was created to run the pipeline, which takes the following flags: species: hg19 datatype: GEX outDir: /path/to/output/dir resume: Y or N run_cellranger: Y or N stubrun: Y or N Examples: # run GEX on test data, for the first time sh run_scRNA.sh hg19 GEX N /path/to/output/dir # first pass, with and without cellranger sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N # resume, with and without cellranger sh run_scRNA.sh hg19 GEX /path/to/output/dir Y Y N sh run_scRNA.sh hg19 GEX /path/to/output/dir Y N N # first pass, with cellranger, with and without a dryrun sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y Y sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N","title":"3. Running the Pipeline"},{"location":"user-guide/run/#3-running-the-pipeline","text":"","title":"3. Running the Pipeline"},{"location":"user-guide/run/#31-pipeline-overview","text":"The Nextflow workflow can be run as follows: nextflow run main.nf \\ -entry $datatype \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /data/sevillas2/scRNA_test \\ --species $species \\ $args","title":"3.1 Pipeline Overview"},{"location":"user-guide/run/#32-commands-explained","text":"The following explains each of the command options: entry: accepts the datatype to be used; IE gex profile: how to run the processes; IE biowulf singularity, docker input: input_manifest.csv location contrast: contrast_manifest.csv location outdir: complete path to the output dir species: species to be used run_cellranger: whether or not to run cellranger on dataset; IE Y, N args: any additional arguments; IE --stub-run","title":"3.2 Commands explained"},{"location":"user-guide/run/#33-typical-workflow","text":"A typical command workflow, running the pipeline for the first time locally, is as follows: nextflow run main.nf \\ -entry gex \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --species hg19 A typical command workflow, running the pipeline for a repeated time locally, running cellranger, is as follows: nextflow run main.nf -resume \\ -entry gex \\ -profile biowulf \\ --run_cellranger Y \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --run_cellranger Y \\ --species hg19 A typical command workflow, running the pipeline in a dryrun mode , without running cellranger, is as follows: nextflow run main.nf \\ -entry gex \\ -profile biowulf \\ --run_cellranger Y \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /path/to/scRNA_test \\ --species hg19 \\ --run_cellranger N \\ --stub-run Alternatively a script was created to run the pipeline, which takes the following flags: species: hg19 datatype: GEX outDir: /path/to/output/dir resume: Y or N run_cellranger: Y or N stubrun: Y or N Examples: # run GEX on test data, for the first time sh run_scRNA.sh hg19 GEX N /path/to/output/dir # first pass, with and without cellranger sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N # resume, with and without cellranger sh run_scRNA.sh hg19 GEX /path/to/output/dir Y Y N sh run_scRNA.sh hg19 GEX /path/to/output/dir Y N N # first pass, with cellranger, with and without a dryrun sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y Y sh run_scRNA.sh hg19 GEX /path/to/output/dir N Y N","title":"3.3 Typical Workflow"},{"location":"user-guide/test-info/","text":"Isolation protocol: CG000392 RevA: Isolation of Leukocytes, Bone Marrow and Peripheral Blood Mononuclear Cells for Single Cell RNA Sequencing - Whole Blood Lysis for Granuloctyes track. Whole transcriptome/Gene Expression libraries were generated as described in the Chromium Next GEM Single Cell 3' Reagent Kits v3.1 (Dual Index) User Guide (CG000204 Rev D). TUTORIAL: https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/tutorials/neutrophils SOURCE: https://www.10xgenomics.com/resources/datasets/whole-blood-rbc-lysis-for-pbmcs-neutrophils-granulocytes-3-3-1-standard WB_1 \u00b6 WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_I1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_I2_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_R1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_R2_001.fastq.gz WB_2 \u00b6 WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_I1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_I2_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_R1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_R2_001.fastq.gz WB_3 and WB_4 are copies \u00b6 WB_1 \u2192 WB_3 WB_2 \u2192 WB_4 samples were then subsampled with a set seed \u00b6 WB_1 \u2192 sample1,sample2 \u2192 s100 WB_2 \u2192 sample3,sample4 \u2192 s101 WB_3 \u2192 sample5,sample6 \u2192 s102 WB_4 \u2192 sample7,sample8 \u2192 s103 grouping tests should be \u00b6 group1,group2 group3,group4 group1+group3,group2+group4","title":"5. Running Test Data"},{"location":"user-guide/test-info/#wb_1","text":"WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_I1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_I2_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_R1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L001_R2_001.fastq.gz","title":"WB_1"},{"location":"user-guide/test-info/#wb_2","text":"WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_I1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_I2_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_R1_001.fastq.gz WB_Lysis_Granulocytes_3p_Introns_8kCells_S1_L002_R2_001.fastq.gz","title":"WB_2"},{"location":"user-guide/test-info/#wb_3-and-wb_4-are-copies","text":"WB_1 \u2192 WB_3 WB_2 \u2192 WB_4","title":"WB_3 and WB_4 are copies"},{"location":"user-guide/test-info/#samples-were-then-subsampled-with-a-set-seed","text":"WB_1 \u2192 sample1,sample2 \u2192 s100 WB_2 \u2192 sample3,sample4 \u2192 s101 WB_3 \u2192 sample5,sample6 \u2192 s102 WB_4 \u2192 sample7,sample8 \u2192 s103","title":"samples were then subsampled with a set seed"},{"location":"user-guide/test-info/#grouping-tests-should-be","text":"group1,group2 group3,group4 group1+group3,group2+group4","title":"grouping tests should be"},{"location":"user-guide/troubleshooting/","text":"Troubleshooting \u00b6 Recommended steps to troubleshoot the pipeline. 1.1 Email \u00b6 Check your email for an email regarding pipeline failure. You will receive an email from slurm@biowulf.nih.gov with the subject: Slurm Job_id=[#] Name=CARLISLE Failed, Run time [time], FAILED, ExitCode 1 1.2 Review the log files \u00b6 Review the logs in two ways: Review the master slurm file: This file will be found in the /path/to/results/dir/ and titled slurm-[jobid].out . Reviewing this file will tell you what rule errored, and for any local SLURM jobs, provide error details Review the individual rule log files: After reviewing the master slurm-file, review the specific rules that failed within the /path/to/results/dir/logs/ . Each rule will include a .err and .out file, with the following formatting: {rulename}.{masterjobID}.{individualruleID}.{wildcards from the rule}.{out or err} 1.3 Restart the run \u00b6 After addressing the issue, unlock the output directory, perform another dry-run and check the status of the pipeline, then resubmit to the cluster. nextflow run main.nf \\ -entry $datatype \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /data/sevillas2/scRNA_test \\ --species $species \\ $args 1.4 Contact information \u00b6 If after troubleshooting, the error cannot be resolved, or if a bug is found, please create an issue and send and email to Samantha Chill .","title":"Troubleshooting"},{"location":"user-guide/troubleshooting/#troubleshooting","text":"Recommended steps to troubleshoot the pipeline.","title":"Troubleshooting"},{"location":"user-guide/troubleshooting/#11-email","text":"Check your email for an email regarding pipeline failure. You will receive an email from slurm@biowulf.nih.gov with the subject: Slurm Job_id=[#] Name=CARLISLE Failed, Run time [time], FAILED, ExitCode 1","title":"1.1 Email"},{"location":"user-guide/troubleshooting/#12-review-the-log-files","text":"Review the logs in two ways: Review the master slurm file: This file will be found in the /path/to/results/dir/ and titled slurm-[jobid].out . Reviewing this file will tell you what rule errored, and for any local SLURM jobs, provide error details Review the individual rule log files: After reviewing the master slurm-file, review the specific rules that failed within the /path/to/results/dir/logs/ . Each rule will include a .err and .out file, with the following formatting: {rulename}.{masterjobID}.{individualruleID}.{wildcards from the rule}.{out or err}","title":"1.2 Review the log files"},{"location":"user-guide/troubleshooting/#13-restart-the-run","text":"After addressing the issue, unlock the output directory, perform another dry-run and check the status of the pipeline, then resubmit to the cluster. nextflow run main.nf \\ -entry $datatype \\ -profile biowulf \\ --input assets/input_manifest.csv \\ --contrast assets/contrast_manifest.csv \\ --outdir /data/sevillas2/scRNA_test \\ --species $species \\ $args","title":"1.3 Restart the run"},{"location":"user-guide/troubleshooting/#14-contact-information","text":"If after troubleshooting, the error cannot be resolved, or if a bug is found, please create an issue and send and email to Samantha Chill .","title":"1.4 Contact information"}]}